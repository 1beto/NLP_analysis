{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7bbcecc1-7926-4e8d-951f-00b194f61fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from spacy.tokens import Doc, Token\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45354487-491c-4e5b-b6ad-9af0e09feb97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E090] Extension 'spelling_errors' already exists on Doc. To overwrite the existing extension, set `force=True` on `Doc.set_extension`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Doc\u001b[38;5;241m.\u001b[39mset_extension(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspelling_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, default\u001b[38;5;241m=\u001b[39m[])\n",
      "File \u001b[0;32m~/.conda/envs/env/lib/python3.11/site-packages/spacy/tokens/doc.pyx:163\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.set_extension\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E090] Extension 'spelling_errors' already exists on Doc. To overwrite the existing extension, set `force=True` on `Doc.set_extension`."
     ]
    }
   ],
   "source": [
    "Doc.set_extension(\"spelling_errors\", default=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8922766e-9a6f-449c-8f3d-249820e1a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_raw = pd.read_json('essays.json')\n",
    "\n",
    "base_texts = essays_raw[:2]\n",
    "essays     = essays_raw.dropna(subset = 'text') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4455a4b0-b55c-4fc2-b5fc-f1be742ed939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'title', 'description', 'info', 'url', 'date', 'prompt', 'text',\n",
       "       'final_score', 'criteria_scores', 'review', 'errors', 'comments'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "572e9330-aeff-4add-be78-9461332ca07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[redação sem título]</td>\n",
       "      <td>No livro ''Os treze porquês\" do escritor Jay A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[redação sem título]</td>\n",
       "      <td>Motivos de risada para alguns e de sofrimento ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[redação sem título]</td>\n",
       "      <td>O filme Karatê Kid ilustra bem o que é o bull ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[redação sem título]</td>\n",
       "      <td>A tempos atr s n o viamos muito se fala em bul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[redação sem título]</td>\n",
       "      <td>No livro ''O Cortiço'', de Aluísio de Azevedo,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                               text\n",
       "2  [redação sem título]  No livro ''Os treze porquês\" do escritor Jay A...\n",
       "3  [redação sem título]  Motivos de risada para alguns e de sofrimento ...\n",
       "4  [redação sem título]  O filme Karatê Kid ilustra bem o que é o bull ...\n",
       "5  [redação sem título]  A tempos atr s n o viamos muito se fala em bul...\n",
       "6  [redação sem título]  No livro ''O Cortiço'', de Aluísio de Azevedo,..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "767c1402-8f49-4eff-a93d-73b6edacdb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23206/3358026284.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  essays_short['tokens'] = tokens\n",
      "/tmp/ipykernel_23206/3358026284.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  essays_short['lemmas'] = lemmas\n",
      "/tmp/ipykernel_23206/3358026284.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  essays_short['pos'] = pos\n",
      "/tmp/ipykernel_23206/3358026284.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  essays_short['sents'] = sents\n",
      "/tmp/ipykernel_23206/3358026284.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  essays_short['ner'] = ner\n",
      "/tmp/ipykernel_23206/3358026284.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  essays_short['token_count'] = token_count\n",
      "/tmp/ipykernel_23206/3358026284.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  essays_short['tokens_nostop_count'] = token_nostop_count\n",
      "/tmp/ipykernel_23206/3358026284.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  essays_short['lemmas_count'] = lemmas_count\n",
      "/tmp/ipykernel_23206/3358026284.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  essays_short['pos_count'] = pos_count\n",
      "/tmp/ipykernel_23206/3358026284.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  essays_short['sents_count'] = sents_count\n",
      "/tmp/ipykernel_23206/3358026284.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  essays_short['ner_count'] = ner_count\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nessays['tokens'] = tokens\\nessays['token_count'] = token_count\\nessays['tokens_nostop_count'] = tokens_nostop_count\\nessays['lemmas'] = lemmas\\nessays['pos'] = pos\\nessays['sents'] = sents\\nessays['ner'] = ner\\n\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar o modelo spaCy para o português\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "errors             = []\n",
    "n_error            = []\n",
    "tokens             = []\n",
    "token_count        = []\n",
    "token_nostop_count = []\n",
    "lemmas             = []\n",
    "lemmas_count       = []\n",
    "pos                = []\n",
    "pos_count          = []\n",
    "sents              = []\n",
    "sents_count        = []\n",
    "ner                = []\n",
    "ner_count          = []\n",
    "\n",
    "n = 100#len(essays)\n",
    "essays_short = essays[:n]\n",
    "\n",
    "i=0\n",
    "for essay in essays['text'][:n]:\n",
    "    tokens.append(list(token.text for token in nlp(essay)))\n",
    "    lemmas.append(list(token.lemma_ for token in nlp(essay)))\n",
    "    pos.append(list(token.pos_ for token in nlp(essay)))\n",
    "    sents.append(list(sent.text for sent in nlp(essay).sents))\n",
    "    ner.append(list((ent.text, ent.label_) for ent in nlp(essay).ents))\n",
    "\n",
    "    token_count.append(len(tokens[-1]))\n",
    "    token_nostop_count.append(len([token for token in nlp(essay) if not token.is_stop]))\n",
    "    lemmas_count.append(len(lemmas[-1]))\n",
    "    pos_count.append(len(pos[-1]))\n",
    "    sents_count.append(len(sents[-1]))\n",
    "    ner_count.append(len(ner[-1]))\n",
    "\n",
    "    i += 1\n",
    "\n",
    "essays_short['tokens'] = tokens\n",
    "essays_short['lemmas'] = lemmas\n",
    "essays_short['pos'] = pos\n",
    "essays_short['sents'] = sents\n",
    "essays_short['ner'] = ner\n",
    "\n",
    "essays_short['token_count'] = token_count\n",
    "essays_short['tokens_nostop_count'] = token_nostop_count\n",
    "essays_short['lemmas_count'] = lemmas_count\n",
    "essays_short['pos_count'] = pos_count\n",
    "essays_short['sents_count'] = sents_count\n",
    "essays_short['ner_count'] = ner_count\n",
    "\n",
    "\"\"\"\n",
    "essays['tokens'] = tokens\n",
    "essays['token_count'] = token_count\n",
    "essays['tokens_nostop_count'] = tokens_nostop_count\n",
    "essays['lemmas'] = lemmas\n",
    "essays['pos'] = pos\n",
    "essays['sents'] = sents\n",
    "essays['ner'] = ner\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0df8618c-59a4-4c2e-9fe1-72581c9999af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essays = essays_short[:int(0.8*len(essays_short))] \n",
    "train_scores = essays_short[['final_score', 'criteria_scores']][:int(0.8*len(essays_short))]\n",
    "\n",
    "test_essays = essays_short[int(0.8*len(essays_short)):] \n",
    "test_scores = essays_short[['final_score', 'criteria_scores']][int(0.8*len(essays_short)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "07f0de98-8b9b-491b-bfcd-44cdd648e5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 6)\n",
      "2     300.0\n",
      "3     300.0\n",
      "4     400.0\n",
      "5     200.0\n",
      "6     850.0\n",
      "      ...  \n",
      "83    600.0\n",
      "84    300.0\n",
      "85    500.0\n",
      "86    600.0\n",
      "87    450.0\n",
      "Name: final_score, Length: 80, dtype: object\n",
      "Mean Squared Error: 46090.225792103\n",
      "R-squared: -1.0973936651696476\n"
     ]
    }
   ],
   "source": [
    "# Selecionar as features\n",
    "features = ['token_count', 'tokens_nostop_count', 'lemmas_count', 'pos_count', 'sents_count', 'ner_count']#,'token']\n",
    "\n",
    "# Definir variáveis de entrada (X) e variável de saída (y) para treinamento\n",
    "X_train = train_essays[features]\n",
    "y_train = train_scores['final_score']\n",
    "\n",
    "# Definir variáveis de entrada (X) e variável de saída (y) para teste\n",
    "X_test = test_essays[features]\n",
    "y_test = test_scores['final_score']\n",
    "\"\"\"\n",
    "# Função para obter a média dos embeddings de palavras em uma frase\n",
    "def get_sentence_embedding(sentence):\n",
    "    tokens = nlp(sentence)\n",
    "    return np.mean([token.vector for token in tokens if token.has_vector], axis=0)\n",
    "\n",
    "# Aplicar a função para obter os embeddings das redações\n",
    "X_train_text_embeddings = X_train['tokens'].apply(lambda tokens: get_sentence_embedding(\" \".join(tokens)) if tokens else np.zeros(300))\n",
    "X_test_text_embeddings = X_test['tokens'].apply(lambda tokens: get_sentence_embedding(\" \".join(tokens)) if tokens else np.zeros(300))\n",
    "\n",
    "print(X_train_text_embeddings)\n",
    "\n",
    "# Converter os embeddings de palavras para um DataFrame\n",
    "X_train_text = pd.DataFrame(X_train_text_embeddings.tolist(), columns=[f'emb_{i}' for i in range(96)])\n",
    "X_test_text = pd.DataFrame(X_test_text_embeddings.tolist(), columns=[f'emb_{i}' for i in range(96)])\n",
    "\n",
    "# Concatenar os embeddings de palavras com as outras features\n",
    "X_train = pd.concat([X_train.drop(columns='tokens'), X_train_text], axis=1)\n",
    "X_test = pd.concat([X_test.drop(columns='tokens'), X_test_text], axis=1)\n",
    "\n",
    "# Substituir possíveis valores infinitos ou NaNs por 0\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)\n",
    "\"\"\"\n",
    "print(X_train.shape)\n",
    "print(y_train)\n",
    "\n",
    "# Treinar um modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho do modelo\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d14b67-7a1d-4b57-931d-75c201b1d03f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cenv",
   "language": "python",
   "name": "cenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
